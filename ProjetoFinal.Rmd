---
title: "Projeto Final de Processamento e Visualização de Dados"
author: "Grupo: Felipe, Lucas e Rafael"
date: "01/03/2022"
output: html_document
---

## Importando Dados

```{r Importando Dados e Bibliotecas}
library(VIM)
library(outliers)
library(EnvStats)
library(tidyverse)

library(devtools)
install_github("vqv/ggbiplot")
library(ggbiplot)

data <- read_csv("data_cleaned_2021.csv")
set.seed(10)
```

## Dados Faltantes

A seguir, transformamos os valores faltantes em nosso *dataset* - no caso -1 e "na" - para a constante NA, de modo a facilitar suas localizações e quantidades pelo uso de funções já definidas em R.

### Calculando Quantidade

```{r Dados Faltantes}

# Transformando strings "na" e inteiros -1 em NA.
for(i in 1:ncol(data)){
  data[(data[,i]=="na" | data[,i]==-1),i] <- NA

}

# Funcao que verifica a quantidade de dados faltantes por coluna, devolvendo as informacoes em um 'tibble'.
verifica_faltantes <- function(data){
  num_faltantes <-c()    # Numero de observacoes faltantes.
  prop_faltantes <- c()  # Proporcao de dados faltantes.
  for (i in 1:ncol(data)) {
    num_nas =  sum(is.na(data[,i]))
    num_faltantes <- append(num_faltantes,num_nas)
    prop_faltantes <- append(prop_faltantes, num_nas * 100/nrow(data))
    print(paste0("A coluna ",colnames(data[i]), " possui ",num_nas," dados faltantes"))
  }
  faltantes <- tibble(colunas = names(data),num_faltantes = num_faltantes, prop_faltantes = prop_faltantes)
  return(faltantes)
  
}

# Chama a function para analise.
faltantes <- verifica_faltantes(data)
```

### Visualizando Dados

A seguir, será gerada uma imagem, buscando exibir esses dados de forma visual, melhorarndo a sensaçao da quantidade de atributos faltantes.

```{r Plotando Dados Faltantes}
toBinaryMatrix <- function(df) {
  m <- c()
  for(i in colnames(df)){
    x <- sum(is.na(data[,i]))
    # missing value count
    m <- append(m,x)
    # non-missing value count
    m <- append(m,nrow(df)-x)
  }
  # adding column and row names to matrix
  a<-matrix(m,nrow=2)
  rownames(a)<-c("TRUE","FALSE")
  colnames(a)<-colnames(df)
  
  return(a)
}

binData <- toBinaryMatrix(data)

barplot(binData,
        main = "Valores faltantes no conjunto de dados",xlab = "Atributos",
        col = c("#0060E5","#14CE75"))

# legend for barplot
legend("topright",
       c("Valores totais","Valores faltantes"),
       fill = c("#0060E5","#14CE75"))
```

### Imputando valores faltantes para aqueles > 5%

A seguir, conforme descrito na especificação do trabalho, *para os atributos que possuam uma porcentagem maior que 5% de valores faltantes, deve ser proposta uma forma de tratá-los"*. Com isso, conforme explicitado no artigo em desenvolvimento, temos 3 tipos de atributos para aplicar 3 tipos de imputação.

```{r Imputação Constante}

# Imputacao de valores contínuos e inteiros
data$Rating[is.nan(data$Rating)] <- mean(data$Rating, na.rm = TRUE)
data$Founded[is.nan(data$Founded)] <- median(data$Founded, na.rm = TRUE)
data$Age[is.nan(data$Age)] <- as.integer(mean(data$Age, na.rm = TRUE))

# Remocao do atributo 'Competitors', 'seniority\_by\_title' e 'Degree' por serem superiores a 60%
data$Competitors <- NULL
data$seniority_by_title <- NULL
data$Degree <- NULL

# Imputacao dos valores do tipo 'string' a partir do uso do kNN
data <- kNN(data)

## Removendo colunas extras inseridas pelo kNN
data <- select(data, -c(39:78))

faltantes <- verifica_faltantes(data)
```

## Ruidos e Outliers

A secção a seguir destina-se a realizar os testes com a finalidade de descobrir a presença de outliers e dados ruidosos.

```{r Ruidos e Outliers}

eh_binario <- apply(data, 2, function(x) {all(x %in% 0:1)})
nomes_colunas <- colnames(data)

outliers_com_grubbs <- function(column) {
  print(paste0("-----Aplicando o Teste de Grubbs-----"))
  grubbs <- grubbs.test(column, opposite = FALSE)
  print(grubbs)
  grubbs <- grubbs.test(column, opposite = TRUE)
  print(grubbs)
}

outliers_com_dixon <- function(column) {
  sub_data <- sample(column, size = 30, replace = FALSE)
  print(paste0("-----Aplicando o Teste de Dixon-----"))
  dixon <- dixon.test(sub_data, opposite = FALSE)
  print(dixon)
  dixon <- dixon.test(sub_data, opposite = TRUE)
  print(dixon)
}

outliers_com_rosner <- function(column) {
  print(paste0("-----Aplicando o Teste de Rosner-----"))
  rosner <- rosnerTest(column, k = 6)
  print(rosner$all.stats)
}

outliers_com_Hampel <- function(column, colName) {
  cat("\n")
  print(paste0("-----Aplicando o Filtro de Hampel-----"))
  limite_min = median(column) - 3 * mad(column)
  limite_max = median(column) + 3 * mad(column)
  
  df_Filtro_de_Hampel <- data %>% filter(column < limite_min | column > limite_max) %>% select(index, colName)
  print(df_Filtro_de_Hampel)
}

for(i in 2:ncol(data)){
  if ((typeof(data[1,i]) != "character") & !eh_binario[nomes_colunas[i]]) {
    print(paste0("************************************"))
    print(paste0("Testando outliers em ", colnames(data[i]), "."))
    print(paste0("************************************"))
    outliers_com_grubbs(data[,i])
    outliers_com_dixon(data[,i])
    outliers_com_rosner(data[,i])
    outliers_com_Hampel(data[,i], nomes_colunas[i])
    cat("\n\n")
  }
}

```

### Redução de dados

Para a redução dos dados, será utilizado o algoritmo PCA sobre o subconjunto de dados referente as tecnologias das vagas.

Pela análise dos resultados obtidos do PCA, em especial pela variância, é possível observar que esse subconjunto de dados possa ser razoavelmente bem representado a partir de 8 componentes principais gerados pelo PCA, permitindo uma representatividade de ~74%.A plotagem desses dados seria possível em um plano de 8 dimensões, algo visivelmente difícil de se compreender. Em contrapartida, o uso de 3 componentes permite um plano tridimensional, mas é capaz de representar apenas ~43% do total de dados.

Dessa forma, é evidente que a utilização do PCA para visualização de dados nesse caso não é muito

```{r Reducao de dados}
requirements <- select(data, Python, spark, aws, excel, sql, sas, keras, pytorch, scikit, tensor, hadoop, tableau, bi, flink, mongo, google_an)

requirements_pca <- prcomp(requirements, center = TRUE, scale. = TRUE)

as.data.frame(requirements_pca$x)

summary(requirements_pca)
```

```{r Imagem de 3 componentes}
ggbiplot(requirements_pca)
```